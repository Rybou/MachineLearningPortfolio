{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP 551 P2: Supervised learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group  47\n",
    "#### Authors : Humayun Khan Kakar, Boury Mbodj & Michael Segev\n",
    "#### Date : Feb 20 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subject: The given file contains the different supervised learning models(logistic regression, decision trees support vector machines and neural networks) that we tried during the project as well as their respective performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos= [x for x in os.listdir(\"train/pos/\") if x.endswith(\".txt\")]\n",
    "neg= [x for x in os.listdir(\"train/neg/\") if x.endswith(\".txt\")]\n",
    "test= [x for x in os.listdir(\"test/\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "posReviews=[]\n",
    "for txt in pos:\n",
    "    with open(\"train/pos/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        posReviews.append(f.read())\n",
    "negReviews=[]        \n",
    "for txt in neg:\n",
    "    with open(\"train/neg/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        negReviews.append(f.read())\n",
    "testReviews=[]        \n",
    "for txt in test:\n",
    "    with open(\"test/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        testReviews.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end data processing \n",
    "reviews = pd.concat([\n",
    "    pd.DataFrame({\"file\":pos,\"review\":posReviews, \"label\":1}),\n",
    "    pd.DataFrame({\"file\":neg,\"review\":negReviews, \"label\":0}),\n",
    "    pd.DataFrame({\"file\":test,\"review\":testReviews, \"label\":-1})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>11119</td>\n",
       "      <td>This movie is a desperate attempt to ride the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>19058</td>\n",
       "      <td>The first time I ever saw this movie was when ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>18629</td>\n",
       "      <td>This movie will send chills down your spine, e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>2501</td>\n",
       "      <td>I saw this on TV the other nightÂ",
       " or rather I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>9728</td>\n",
       "      <td>I am a huge fan of Simon Pegg and have watched...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>12340</td>\n",
       "      <td>There is indeed much to complain about this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>6894</td>\n",
       "      <td>The men can slaver over Lollo, if they like (o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>11987</td>\n",
       "      <td>Since it has been some years since I reviewed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>10543</td>\n",
       "      <td>Wow, what exciting visual effects. I also love...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>9197</td>\n",
       "      <td>This is actually a groovy-neat little flick, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                             review  label\n",
       "26247  11119  This movie is a desperate attempt to ride the ...     -1\n",
       "35067  19058  The first time I ever saw this movie was when ...     -1\n",
       "34590  18629  This movie will send chills down your spine, e...     -1\n",
       "16668   2501  I saw this on TV the other nightÂ\n",
       " or rather I...      0\n",
       "12196   9728  I am a huge fan of Simon Pegg and have watched...      1\n",
       "2600   12340  There is indeed much to complain about this mo...      1\n",
       "9047    6894  The men can slaver over Lollo, if they like (o...      1\n",
       "2206   11987  Since it has been some years since I reviewed ...      1\n",
       "25607  10543  Wow, what exciting visual effects. I also love...     -1\n",
       "11606   9197  This is actually a groovy-neat little flick, m...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine firts 10 rows\n",
    "reviews[\"file\"]= reviews[\"file\"].str.split(\"_\", n = 1, expand = True)\n",
    "reviews[\"file\"]= reviews[\"file\"].str.split(\".\", n = 1, expand = True)\n",
    "#reviews.set_index('file',inplace=True)\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    25000\n",
       " 1    12500\n",
       " 0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the class ditribution \n",
    "reviews.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we process the text\n",
    "# We use BeautifulSoup library to remove the HTML/XML tags (e.g., <br />) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    #text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "reviews['review'] = reviews.review.apply(lambda x: process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>11119</td>\n",
       "      <td>This movie be a desperate attempt to ride the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>19058</td>\n",
       "      <td>The first time I ever saw this movie wa when I...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>18629</td>\n",
       "      <td>This movie will send chill down your spine eve...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>2501</td>\n",
       "      <td>I saw this on TV the other nightÂ",
       " or rather I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>9728</td>\n",
       "      <td>I be a huge fan of Simon Pegg and have watch p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>12340</td>\n",
       "      <td>There be indeed much to complain about this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>6894</td>\n",
       "      <td>The men can slaver over Lollo if they like or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>11987</td>\n",
       "      <td>Since it ha be some year since I review this c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>10543</td>\n",
       "      <td>Wow what excite visual effect I also love the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>9197</td>\n",
       "      <td>This be actually a groovyneat little flick mak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                             review  label\n",
       "26247  11119  This movie be a desperate attempt to ride the ...     -1\n",
       "35067  19058  The first time I ever saw this movie wa when I...     -1\n",
       "34590  18629  This movie will send chill down your spine eve...     -1\n",
       "16668   2501  I saw this on TV the other nightÂ\n",
       " or rather I...      0\n",
       "12196   9728  I be a huge fan of Simon Pegg and have watch p...      1\n",
       "2600   12340  There be indeed much to complain about this mo...      1\n",
       "9047    6894  The men can slaver over Lollo if they like or ...      1\n",
       "2206   11987  Since it ha be some year since I review this c...      1\n",
       "25607  10543  Wow what excite visual effect I also love the ...     -1\n",
       "11606   9197  This be actually a groovyneat little flick mak...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the text after feature extractrion\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y from the review dataset  for use with Countvectorizer\n",
    "X= reviews[reviews.label!=-1].review\n",
    "y= reviews[reviews.label!=-1].label\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(2500,)\n",
      "(22500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into training and testing/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vectorizer for n-garms with TD-IDF with l2 regularization\n",
    "vect = TfidfVectorizer(min_df=5, max_df = 0.85, sublinear_tf=True, use_idf =True, ngram_range=(1, 4), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn training data vocabulary fit then use to create document term matrix\n",
    "X_train_dtm= vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x247528 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 807961 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logitic regression model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log=logmodel.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decison tree model\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtree=dtree.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector machines \n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmmodel = SVC(kernel='rbf', C = 10.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmmodel.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm=svmmodel.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpcmodel = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpcmodel.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlpc=mlpcmodel.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics to calculate accuracy\n",
    "from sklearn import metrics\n",
    "#Now for the classification task we are going to import classification report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.9036\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      1248\n",
      "           1       0.90      0.91      0.90      1252\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2500\n",
      "   macro avg       0.90      0.90      0.90      2500\n",
      "weighted avg       0.90      0.90      0.90      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1118  130]\n",
      " [ 111 1141]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for Logistic regr\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_log))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_log))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for decision trees :\n",
      "0.7196\n",
      "Classification score for decision trees  :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      1248\n",
      "           1       0.72      0.72      0.72      1252\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      2500\n",
      "   macro avg       0.72      0.72      0.72      2500\n",
      "weighted avg       0.72      0.72      0.72      2500\n",
      "\n",
      "Confusion matrix for decision trees  :\n",
      "[[896 352]\n",
      " [349 903]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 2\n",
    "print(\"Accuracy score for decision trees :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_dtree))\n",
    "print(\"Classification score for decision trees  :\")\n",
    "print(classification_report(y_test,y_pred_dtree))\n",
    "print(\"Confusion matrix for decision trees  :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_dtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for support vector machines :\n",
      "0.9168\n",
      "Classification score support vector machines :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1248\n",
      "           1       0.92      0.92      0.92      1252\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2500\n",
      "   macro avg       0.92      0.92      0.92      2500\n",
      "weighted avg       0.92      0.92      0.92      2500\n",
      "\n",
      "Confusion matrix support vector machines :\n",
      "[[1143  105]\n",
      " [ 103 1149]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 3\n",
    "print(\"Accuracy score for support vector machines :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_svm))\n",
    "print(\"Classification score support vector machines :\")\n",
    "print(classification_report(y_test,y_pred_svm))\n",
    "print(\"Confusion matrix support vector machines :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for neural networks :\n",
      "0.9176\n",
      "Classification score neural networks :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1248\n",
      "           1       0.92      0.92      0.92      1252\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2500\n",
      "   macro avg       0.92      0.92      0.92      2500\n",
      "weighted avg       0.92      0.92      0.92      2500\n",
      "\n",
      "Confusion matrix neural networks  :\n",
      "[[1147  101]\n",
      " [ 105 1147]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 4\n",
    "print(\"Accuracy score for neural networks :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_mlpc))\n",
    "print(\"Classification score neural networks :\")\n",
    "print(classification_report(y_test,y_pred_mlpc))\n",
    "print(\"Confusion matrix neural networks  :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_mlpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
