{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMP 551 P2: Feature extraction and validation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group  47\n",
    "#### Authors : Humayun Khan Kakar , Boury Mbodj & Michael Segev \n",
    "#### Date : Feb 20 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subject: The given file contains the different feature extraction models (binary , td-idf) and validation (held out , k-fold validation) models that we  tried during the project as well as their respective performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos= [x for x in os.listdir(\"train/pos/\") if x.endswith(\".txt\")]\n",
    "neg= [x for x in os.listdir(\"train/neg/\") if x.endswith(\".txt\")]\n",
    "test= [x for x in os.listdir(\"test/\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "posReviews=[]\n",
    "for txt in pos:\n",
    "    with open(\"train/pos/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        posReviews.append(f.read())\n",
    "negReviews=[]        \n",
    "for txt in neg:\n",
    "    with open(\"train/neg/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        negReviews.append(f.read())\n",
    "testReviews=[]        \n",
    "for txt in test:\n",
    "    with open(\"test/\"+txt, encoding=\"ISO-8859-1\") as f:\n",
    "        testReviews.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end data processing \n",
    "reviews = pd.concat([\n",
    "    pd.DataFrame({\"file\":pos,\"review\":posReviews, \"label\":1}),\n",
    "    pd.DataFrame({\"file\":neg,\"review\":negReviews, \"label\":0}),\n",
    "    pd.DataFrame({\"file\":test,\"review\":testReviews, \"label\":-1})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>11119</td>\n",
       "      <td>This movie is a desperate attempt to ride the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>19058</td>\n",
       "      <td>The first time I ever saw this movie was when ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>18629</td>\n",
       "      <td>This movie will send chills down your spine, e...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>2501</td>\n",
       "      <td>I saw this on TV the other nightÂ",
       " or rather I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>9728</td>\n",
       "      <td>I am a huge fan of Simon Pegg and have watched...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>12340</td>\n",
       "      <td>There is indeed much to complain about this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>6894</td>\n",
       "      <td>The men can slaver over Lollo, if they like (o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>11987</td>\n",
       "      <td>Since it has been some years since I reviewed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>10543</td>\n",
       "      <td>Wow, what exciting visual effects. I also love...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>9197</td>\n",
       "      <td>This is actually a groovy-neat little flick, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                             review  label\n",
       "26247  11119  This movie is a desperate attempt to ride the ...     -1\n",
       "35067  19058  The first time I ever saw this movie was when ...     -1\n",
       "34590  18629  This movie will send chills down your spine, e...     -1\n",
       "16668   2501  I saw this on TV the other nightÂ\n",
       " or rather I...      0\n",
       "12196   9728  I am a huge fan of Simon Pegg and have watched...      1\n",
       "2600   12340  There is indeed much to complain about this mo...      1\n",
       "9047    6894  The men can slaver over Lollo, if they like (o...      1\n",
       "2206   11987  Since it has been some years since I reviewed ...      1\n",
       "25607  10543  Wow, what exciting visual effects. I also love...     -1\n",
       "11606   9197  This is actually a groovy-neat little flick, m...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine firts 10 rows\n",
    "reviews[\"file\"]= reviews[\"file\"].str.split(\"_\", n = 1, expand = True)\n",
    "reviews[\"file\"]= reviews[\"file\"].str.split(\".\", n = 1, expand = True)\n",
    "#reviews.set_index('file',inplace=True)\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    25000\n",
       " 1    12500\n",
       " 0    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the class ditribution \n",
    "reviews.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we process the text\n",
    "# We use BeautifulSoup library to remove the HTML/XML tags (e.g., <br />) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    #text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "reviews['review'] = reviews.review.apply(lambda x: process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26247</th>\n",
       "      <td>11119</td>\n",
       "      <td>This movie be a desperate attempt to ride the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>19058</td>\n",
       "      <td>The first time I ever saw this movie wa when I...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>18629</td>\n",
       "      <td>This movie will send chill down your spine eve...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>2501</td>\n",
       "      <td>I saw this on TV the other nightÂ",
       " or rather I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>9728</td>\n",
       "      <td>I be a huge fan of Simon Pegg and have watch p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>12340</td>\n",
       "      <td>There be indeed much to complain about this mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>6894</td>\n",
       "      <td>The men can slaver over Lollo if they like or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>11987</td>\n",
       "      <td>Since it ha be some year since I review this c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>10543</td>\n",
       "      <td>Wow what excite visual effect I also love the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>9197</td>\n",
       "      <td>This be actually a groovyneat little flick mak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file                                             review  label\n",
       "26247  11119  This movie be a desperate attempt to ride the ...     -1\n",
       "35067  19058  The first time I ever saw this movie wa when I...     -1\n",
       "34590  18629  This movie will send chill down your spine eve...     -1\n",
       "16668   2501  I saw this on TV the other nightÂ\n",
       " or rather I...      0\n",
       "12196   9728  I be a huge fan of Simon Pegg and have watch p...      1\n",
       "2600   12340  There be indeed much to complain about this mo...      1\n",
       "9047    6894  The men can slaver over Lollo if they like or ...      1\n",
       "2206   11987  Since it ha be some year since I review this c...      1\n",
       "25607  10543  Wow what excite visual effect I also love the ...     -1\n",
       "11606   9197  This be actually a groovyneat little flick mak...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the text after feature extractrion\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y from the review dataset  for use with Countvectorizer\n",
    "X= reviews[reviews.label!=-1].review\n",
    "y= reviews[reviews.label!=-1].label\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(2500,)\n",
      "(22500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into training and testing/validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vectorizer  for binary features\n",
    "vect = CountVectorizer(min_df=5, max_df = 0.85, ngram_range=(1, 4), strip_accents='unicode', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn training data vocabulary fit then use to create document term matrix\n",
    "X_train_dtm= vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22500x247549 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7447438 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x247549 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 807993 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vectorizer for n-garms without binary \n",
    "vect2 = CountVectorizer(min_df=5, max_df = 0.85, ngram_range=(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn training data vocabulary fit then use to create document term matrix\n",
    "X_train_dtm2= vect2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22500x247528 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7447142 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix for the second feature design\n",
    "X_train_dtm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x247528 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 807961 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm2 = vect2.transform(X_test)\n",
    "X_test_dtm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vectorizer for n-garms with TD-IDF \n",
    "vect3 = TfidfVectorizer(min_df=5, max_df = 0.85, use_idf =True, ngram_range=(1, 4), norm='l2',strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn training data vocabulary fit then use to create document term matrix\n",
    "X_train_dtm3= vect3.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22500x247549 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7447438 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix for the third feature design\n",
    "X_train_dtm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x247549 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 807993 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm3 = vect3.transform(X_test)\n",
    "X_test_dtm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logitic regression model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log=logmodel.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel2=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel2.fit(X_train_dtm2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log2=logmodel2.predict(X_test_dtm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel3=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel3.fit(X_train_dtm3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log3=logmodel3.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(penalty=\"l2\", C=1), param_grid, cv=5)\n",
    "grid.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid=grid.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2 = GridSearchCV(LogisticRegression(penalty=\"l2\", C=1), param_grid, cv=5)\n",
    "grid2.fit(X_train_dtm2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid2=grid2.predict(X_test_dtm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid3 = GridSearchCV(LogisticRegression(penalty=\"l2\", C=1), param_grid, cv=5)\n",
    "grid3.fit(X_train_dtm3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_grid3=grid3.predict(X_test_dtm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics to calculate accuracy\n",
    "from sklearn import metrics\n",
    "#Now for the classification task we are going to import classification report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.8964\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1248\n",
      "           1       0.89      0.90      0.90      1252\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2500\n",
      "   macro avg       0.90      0.90      0.90      2500\n",
      "weighted avg       0.90      0.90      0.90      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1116  132]\n",
      " [ 127 1125]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 1\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_log))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_log))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.9004\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1248\n",
      "           1       0.90      0.90      0.90      1252\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2500\n",
      "   macro avg       0.90      0.90      0.90      2500\n",
      "weighted avg       0.90      0.90      0.90      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1129  119]\n",
      " [ 130 1122]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 2\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_log2))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_log2))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_log2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.8696\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      1248\n",
      "           1       0.92      0.81      0.86      1252\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2500\n",
      "   macro avg       0.87      0.87      0.87      2500\n",
      "weighted avg       0.87      0.87      0.87      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1155   93]\n",
      " [ 233 1019]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 3\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_log3))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_log3))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_log3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.8964\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1248\n",
      "           1       0.89      0.90      0.90      1252\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2500\n",
      "   macro avg       0.90      0.90      0.90      2500\n",
      "weighted avg       0.90      0.90      0.90      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1116  132]\n",
      " [ 127 1125]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 3\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_grid))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_grid))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.9044\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      1248\n",
      "           1       0.90      0.91      0.90      1252\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      2500\n",
      "   macro avg       0.90      0.90      0.90      2500\n",
      "weighted avg       0.90      0.90      0.90      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1126  122]\n",
      " [ 117 1135]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 3\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_grid2))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_grid2))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_grid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for logistic regression :\n",
      "0.9152\n",
      "Classification score for logistic regression :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      1248\n",
      "           1       0.91      0.92      0.92      1252\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2500\n",
      "   macro avg       0.92      0.92      0.92      2500\n",
      "weighted avg       0.92      0.92      0.92      2500\n",
      "\n",
      "Confusion matrix for logistic regression :\n",
      "[[1140  108]\n",
      " [ 104 1148]]\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy, classification report and confusion metrics for model 3\n",
    "print(\"Accuracy score for logistic regression :\")\n",
    "print(metrics.accuracy_score(y_test,y_pred_grid3))\n",
    "print(\"Classification score for logistic regression :\")\n",
    "print(classification_report(y_test,y_pred_grid3))\n",
    "print(\"Confusion matrix for logistic regression :\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_grid3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
